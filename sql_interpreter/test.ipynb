{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EXTENSION plpythonu;\n",
    "\n",
    "\n",
    "# CREATE OR REPLACE FUNCTION execute_python_script(python_script text)\n",
    "# RETURNS text\n",
    "# LANGUAGE plpythonu\n",
    "# AS $$\n",
    "# # Execute the Python script\n",
    "# exec_result = plpy.execute(python_script, 1)\n",
    "\n",
    "# return exec_result[0][\"?column?\"]\n",
    "# $$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "\n",
    "# # Replace these with your database connection details\n",
    "# db_host = 'localhost'\n",
    "# db_name = 'TestDataBase'\n",
    "# db_user = 'postgres'\n",
    "# db_password = '2357'\n",
    "\n",
    "# python_script = \"\"\"\n",
    "# print(\"Hello from Python script!\")\n",
    "# \"\"\"\n",
    "\n",
    "# try:\n",
    "#     # Connect to the database\n",
    "#     conn = psycopg2.connect(\n",
    "#         host=db_host,\n",
    "#         database=db_name,\n",
    "#         user=db_user,\n",
    "#         password=db_password\n",
    "#     )\n",
    "\n",
    "#     # Create a cursor\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     # Define the function call\n",
    "#     function_call = \"SELECT * from Employees\"\n",
    "# # execute_python_script('{python_script}')\"\n",
    "\n",
    "#     # Execute the function\n",
    "#     cursor.execute(function_call)\n",
    "\n",
    "#     # Fetch the result\n",
    "#     result = cursor.fetchone()\n",
    "\n",
    "#     # Print the result\n",
    "#     print(\"Result from PostgreSQL:\", result)\n",
    "\n",
    "#     # Close the cursor and the connection\n",
    "#     cursor.close()\n",
    "#     conn.close()\n",
    "\n",
    "# except (Exception, psycopg2.Error) as error:\n",
    "#     print(\"Error while connecting to PostgreSQL:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import os\n",
    "\n",
    "import ast\n",
    "\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "\n",
    "from contextlib import suppress\n",
    "\n",
    "openai.api_key= '46d7ed565dda46f1893e7d0e42b3aefb'\n",
    "openai.api_base = 'https://openaiautomationteam.openai.azure.com/'\n",
    "openai.api_type= 'azure'\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "\n",
    "# STOP = os.getenv('STOP', \"\")\n",
    "# MAX_TOKENS = float(os.getenv('MAX_TOKENS', 500))\n",
    "# TOP_P = int(os.environ.get('TOP_P', 1))\n",
    "# FREQUENCY_PENALTY = int(os.getenv('FREQUENCY_PENALTY', 0))\n",
    "# PRESENCE_PENALTY = int(os.getenv('PRESENCE_PENALTY', 0))\n",
    "# N_RESP = int(os.getenv('N_RESP', 1))\n",
    "# TIMEOUT = int(os.getenv('TIMEOUT', 60))\n",
    "\n",
    "DB_HOST = os.environ.get('DB_HOST', None)\n",
    "DB_PORT = os.environ.get('DB_PORT', None)\n",
    "DB_USER = os.environ.get('DB_USER', None)\n",
    "DB_PASSWORD = os.environ.get('DB_PASSWORD', None)\n",
    "DB_NAME = os.environ.get('DB_NAME', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PGRESCREDS={'Host': DB_HOST, 'Port': DB_PORT, 'User': DB_USER, 'Password': DB_PASSWORD, 'Name': DB_NAME}\n",
    "\n",
    "Creds = list(PGRESCREDS.values())\n",
    "\n",
    "sql={\"sql\":\"SELECT table_name, column_name, data_type FROM information_schema.columns WHERE table_schema = 'public';\"}\n",
    "\n",
    "\n",
    "sql_key = list(sql.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_function_call(Creds, sql_key, response_message):\n",
    "    '''Function calling for Running the generated python code on PostGRES Server'''\n",
    "\n",
    "\n",
    "    conn = psycopg2.connect(host=Creds[0], database=Creds[4], user=Creds[2], password=Creds[3], port=Creds[1])\n",
    "    \n",
    "    def extract_outermost_dict(s):\n",
    "        for i in range(len(s)):\n",
    "            for j in range(i, len(s)):\n",
    "                substring = s[i:j+1]\n",
    "                try:\n",
    "                    node = ast.literal_eval(substring)\n",
    "                    if isinstance(node, dict):\n",
    "                        return node\n",
    "                except (ValueError, SyntaxError):\n",
    "                    pass\n",
    "        return None\n",
    "    \n",
    "    def extract_json(response_message):\n",
    "        \"\"\"Function to extract JSON from the output response. The JSON is within triple bacticks\n",
    "\n",
    "        Args:\n",
    "            output_response (str): output response\n",
    "\n",
    "        Returns:\n",
    "            dict: json\n",
    "        \"\"\"\n",
    "        json_output = re.findall(r\"```([\\s\\S]*?)```\", response_message)\n",
    "\n",
    "        if len(json_output) == 0:\n",
    "            return ''\n",
    "        elif len(json_output) >= 1:\n",
    "            json_output = json_output[0]\n",
    "        \n",
    "        json_output = extract_outermost_dict(json_output)\n",
    "        return json_output\n",
    "    \n",
    "    def validate_json(self, input_json):\n",
    "        return True, \"The JSON is valid\"\n",
    "\n",
    "    json_output = extract_json(response_message)\n",
    "\n",
    "    def ExecuteSQL(sql_key):\n",
    "        \"\"\"Function to execute SQL query\n",
    "\n",
    "        Args:\n",
    "            sql (str): sql query to execute\n",
    "\n",
    "        Returns:\n",
    "            str: output of sql query\n",
    "        \"\"\"\n",
    "        try:\n",
    "            sql = sql[sql_key[0]] #key\n",
    "            cur = conn.cursor()\n",
    "            # Execute a SQL query\n",
    "            cur.execute(sql)\n",
    "\n",
    "            # Fetch the results\n",
    "            results = cur.fetchall()\n",
    "\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "            if results == '':\n",
    "                return \"PostgresSQL Query executed Successfully\"\n",
    "            else:\n",
    "                ShareOutput(results)\n",
    "                return results\n",
    "        except Exception as e:\n",
    "            return f\"There is some error in SQL query: {str(e)}\"\n",
    "    \n",
    "    def get_database_info(sql_key):\n",
    "        \"\"\"Function to get database and table information using sql queries\n",
    "\n",
    "        Returns:\n",
    "            dict: database info\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = ExecuteSQL(sql_key)\n",
    "            update_history({\"function\":\"ExecuteSQL\",\"parameters\":{\"sql\":\"SELECT table_name, column_name, data_type FROM information_schema.columns WHERE table_schema = 'public';\"}}, result)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def ShareOutput(output: str) -> str:\n",
    "        \"\"\"Function to share output\n",
    "\n",
    "        Args:\n",
    "            output (str): output to share\n",
    "\n",
    "        Returns:\n",
    "            str: output of sharing output\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return output\n",
    "        except Exception as e:\n",
    "            return e\n",
    "\n",
    "    def update_history(input_json: str, output: str) -> str:\n",
    "        \"\"\"\n",
    "        Function to update history\n",
    "\n",
    "        Args:\n",
    "            input_prompt (str): input prompt\n",
    "            output (str): output\n",
    "\n",
    "        Returns:\n",
    "            str: output of updating history\n",
    "        \"\"\"\n",
    "        try:\n",
    "            history = prepare_history(input_json, output)\n",
    "            if history == \"Empty\":\n",
    "                history = [history]\n",
    "            else:\n",
    "                history.append(history)\n",
    "            \n",
    "            for ind, his in enumerate(history, start=1):\n",
    "                history += f\"{ind}. {his}\\n\"\n",
    "\n",
    "            user_prompt = base_user_prompt.replace('<history>', f\"[{history}]\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def prepare_history(input_json: str, output: str) -> str:\n",
    "        \"\"\"Function to prepare history\n",
    "\n",
    "        Args:\n",
    "            input_prompt (str): input prompt\n",
    "            output (str): output\n",
    "\n",
    "        Returns:\n",
    "            str: output of preparing history\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return f\"Assistant Response-\\n{input_json}\\nExecution Output-\\n{output}\\n\"\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    get_database_info(sql_key)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    if json_output == '':\n",
    "        print(response_message)\n",
    "        # break\n",
    "\n",
    "    valid_json, output = validate_json(json_output)\n",
    "\n",
    "\n",
    "    if not valid_json:\n",
    "        update_history(response_message, output)\n",
    "        # continue\n",
    "\n",
    "    function_to_perform = json_output['function']\n",
    "\n",
    "    if 'parameters' in json_output:\n",
    "        function_params = json_output['parameters']\n",
    "\n",
    "    # if function_to_perform == \"Exit\":\n",
    "        # break\n",
    "\n",
    "    supported_functions = {\n",
    "            \"ExecuteSQL\": ExecuteSQL,\n",
    "            \"ShareOutput\": ShareOutput\n",
    "        }\n",
    "    \n",
    "    output = supported_functions[function_to_perform](function_params)\n",
    "    print(output)\n",
    "    \n",
    "    update_history(response_message, output)\n",
    "    \n",
    "    arguments = {\n",
    "\n",
    "        \"Creds\": Creds,\n",
    "\n",
    "        \"sql_key\": sql_key,\n",
    "\n",
    "        \"response_message\": response_message,\n",
    "\n",
    "    }\n",
    "    \n",
    "    json.dumps(arguments)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt=\"Generate a directly python script to plot graphs for a given dataset: 'Data.xlsx' and an explanation of observations in each graph. Give explanation as a paragraph after every graph.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"Data.xlsx\")\n",
    "columns=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "des=data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt=\"Generate a directly python script to plot graphs for a given dataset: 'Data.xlsx' and an explanation of observations in each graph. Give explanation as a paragraph after every graph.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Generate a directly python script to plot graphs for a given dataset: 'Data.xlsx' and an explanation of observations in each graph. Give explanation as a paragraph after every graph.; Columns: Index(['Sales_Rep', 'Business', 'Age', 'Female', 'Years', 'College',\\n       'Personality', 'Certficates', 'Feedback', 'Salary',\\n       'customer-satisfaction-score'],\\n      dtype='object'); Dataset Insights:           Sales_Rep           Age        Female         Years   Certficates  \\\\\\ncount  21990.000000  21990.000000  21990.000000  21990.000000  21990.000000   \\nmean   10995.500000     41.495953      0.383038      2.646385      2.612187   \\nstd     6348.110546     11.413748      0.486138      2.434109      1.648258   \\nmin        1.000000     21.000000      0.000000      1.000000      0.000000   \\n25%     5498.250000     32.000000      0.000000      1.000000      1.000000   \\n50%    10995.500000     41.000000      0.000000      2.000000      2.000000   \\n75%    16492.750000     51.000000      1.000000      2.000000      4.000000   \\nmax    21990.000000     65.000000      1.000000     13.000000      6.000000   \\n\\n           Feedback         Salary  customer-satisfaction-score  \\ncount  21990.000000   21990.000000                 21990.000000  \\nmean       2.664525   73673.778990                     6.278445  \\nstd        0.836770   22769.906232                     2.163074  \\nmin        1.080000   21000.000000                     1.000000  \\n25%        1.990000   57000.000000                     5.000000  \\n50%        2.660000   70000.000000                     6.000000  \\n75%        3.390000   87000.000000                     8.000000  \\nmax        4.000000  197000.000000                    10.000000  \""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = input_prompt+ \"; \" + f\"Columns: {columns}\" +\"; \"+f\"Dataset Insights: {des}\"\n",
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = user_prompt + '''Make sure that every plot gives some major insights of the dataset. Don't use scatter plot for comparison of two features.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = '''You are a data analyst. Call a function 'automate_function_call' which will execute the python code generated to Postgres server and give us the output after execution.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Unrecognized request argument supplied: functions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 30\u001b[0m\n\u001b[1;32m      1\u001b[0m functions \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m         {\n\u001b[1;32m      3\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mautomate_function_call\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m messages \u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m:system_prompt}, {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m:prompt}]\n\u001b[0;32m---> 30\u001b[0m result_GPT \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     31\u001b[0m     \n\u001b[1;32m     32\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDIR_GPT4\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     33\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m,\n\u001b[1;32m     34\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m     35\u001b[0m     functions\u001b[39m=\u001b[39;49mfunctions,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m response_message \u001b[39m=\u001b[39m result_GPT\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(response_message)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Unrecognized request argument supplied: functions"
     ]
    }
   ],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"automate_function_call\",\n",
    "            \"description\": \"Automate the function calling in such a way that history is updated\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Creds\": {\n",
    "                        \"type\": \"list\",\n",
    "                        \"description\": \"Credentials for PostGRES which are used in the function using psycopg2 library\",\n",
    "                    },\n",
    "                    \"sql_key\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The key for the SQL Query to be executed  \"\n",
    "                    },\n",
    "                    \"response_message\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"First response of GPT API for system_prompt and user_prompt\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"Creds\", \"sql_key\", \"response_message\"]\n",
    "            }\n",
    "        }, \n",
    "\n",
    "    ]\n",
    "\n",
    "messages =[{\"role\":\"system\", \"content\":system_prompt}, {\"role\":\"user\", \"content\":prompt}]\n",
    "\n",
    "\n",
    "result_GPT = openai.ChatCompletion.create(\n",
    "    \n",
    "    engine='DIR_GPT4',\n",
    "    temperature=0.7,\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    ")\n",
    "\n",
    "response_message = result_GPT.choices[0].message.content\n",
    "\n",
    "print(response_message)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mif\u001b[39;00m response_message\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m     available_functions \u001b[39m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mautomate_function_call\u001b[39m\u001b[39m\"\u001b[39m: automate_function_call,\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      9\u001b[0m     function_name \u001b[39m=\u001b[39m response_message[\u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response_message' is not defined"
     ]
    }
   ],
   "source": [
    "if response_message.get(\"function_call\"):\n",
    "\n",
    "    available_functions = {\n",
    "\n",
    "        \"automate_function_call\": automate_function_call,\n",
    "\n",
    "    }\n",
    "\n",
    "    function_name = response_message[\"function_call\"][\"name\"]\n",
    "\n",
    "    fuction_to_call = available_functions[function_name]\n",
    "\n",
    "    function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "\n",
    "    function_response = fuction_to_call(\n",
    "\n",
    "\n",
    "        Creds=function_args.get(\"Creds\"),\n",
    "\n",
    "        sql_key=function_args.get(\"sql_key\"),\n",
    "\n",
    "        response_message=function_args.get(\"response_message\"),\n",
    "\n",
    "    )\n",
    "\n",
    "    messages.append(response_message)\n",
    "\n",
    "    messages.append(\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"function\",\n",
    "\n",
    "            \"name\": function_name,\n",
    "\n",
    "            \"content\": function_response,\n",
    "\n",
    "        }\n",
    "\n",
    "    )\n",
    "\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "\n",
    "        engine=\"DIR_GPT4\",\n",
    "\n",
    "        messages=messages,\n",
    "\n",
    "    )\n",
    "\n",
    "print(second_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
